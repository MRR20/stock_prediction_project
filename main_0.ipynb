{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Date       Close\n",
      "Ticker                   AAPL\n",
      "0      2022-10-03  142.449997\n",
      "1      2022-10-04  146.100006\n",
      "2      2022-10-05  146.399994\n",
      "3      2022-10-06  145.429993\n",
      "4      2022-10-07  140.089996\n",
      "Price        Date       Close\n",
      "Ticker                   AAPL\n",
      "539    2024-11-22  229.869995\n",
      "540    2024-11-25  232.869995\n",
      "541    2024-11-26  235.059998\n",
      "542    2024-11-27  234.929993\n",
      "543    2024-11-29  237.330002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define stock symbol and date range\n",
    "stock_symbol = 'AAPL'  # Example: Apple stock\n",
    "start_date = '2022-10-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Download stock data\n",
    "stock_data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "stock_data = stock_data[['Close']].reset_index()  # Keep only 'Date' and 'Close'\n",
    "\n",
    "print(stock_data.head())\n",
    "print(stock_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"1e78027b-d07c-4e35-9a0a-8f1d2b4e5549\"    # \"42650c85-dd10-4ccd-b974-a1832d8902ec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for: 2022-10-01\n",
      "Fetching data for: 2022-10-02\n",
      "Fetching data for: 2022-10-03\n",
      "Fetching data for: 2022-10-04\n",
      "Fetching data for: 2022-10-05\n",
      "Fetching data for: 2022-10-06\n",
      "Fetching data for: 2022-10-07\n",
      "Fetching data for: 2022-10-08\n",
      "Fetching data for: 2022-10-09\n",
      "Fetching data for: 2022-10-10\n",
      "Fetching data for: 2022-10-11\n",
      "Fetching data for: 2022-10-12\n",
      "Fetching data for: 2022-10-13\n",
      "Fetching data for: 2022-10-14\n",
      "Fetching data for: 2022-10-15\n",
      "Fetching data for: 2022-10-16\n",
      "Fetching data for: 2022-10-17\n",
      "Fetching data for: 2022-10-18\n",
      "Fetching data for: 2022-10-19\n",
      "Fetching data for: 2022-10-20\n",
      "Fetching data for: 2022-10-21\n",
      "Fetching data for: 2022-10-22\n",
      "Fetching data for: 2022-10-23\n",
      "Fetching data for: 2022-10-24\n",
      "Fetching data for: 2022-10-25\n",
      "Fetching data for: 2022-10-26\n",
      "Fetching data for: 2022-10-27\n",
      "Fetching data for: 2022-10-28\n",
      "Fetching data for: 2022-10-29\n",
      "Fetching data for: 2022-10-30\n",
      "Fetching data for: 2022-10-31\n",
      "Fetching data for: 2022-11-01\n",
      "Fetching data for: 2022-11-02\n",
      "Fetching data for: 2022-11-03\n",
      "Fetching data for: 2022-11-04\n",
      "Fetching data for: 2022-11-05\n",
      "Fetching data for: 2022-11-06\n",
      "Fetching data for: 2022-11-07\n",
      "Fetching data for: 2022-11-08\n",
      "Fetching data for: 2022-11-09\n",
      "Fetching data for: 2022-11-10\n",
      "Fetching data for: 2022-11-11\n",
      "Fetching data for: 2022-11-12\n",
      "Fetching data for: 2022-11-13\n",
      "Fetching data for: 2022-11-14\n",
      "Fetching data for: 2022-11-15\n",
      "Fetching data for: 2022-11-16\n",
      "Fetching data for: 2022-11-17\n",
      "Fetching data for: 2022-11-18\n",
      "Fetching data for: 2022-11-19\n",
      "Fetching data for: 2022-11-20\n",
      "Fetching data for: 2022-11-21\n",
      "Fetching data for: 2022-11-22\n",
      "Fetching data for: 2022-11-23\n",
      "Fetching data for: 2022-11-24\n",
      "Fetching data for: 2022-11-25\n",
      "Fetching data for: 2022-11-26\n",
      "Fetching data for: 2022-11-27\n",
      "Fetching data for: 2022-11-28\n",
      "Fetching data for: 2022-11-29\n",
      "Fetching data for: 2022-11-30\n",
      "Fetching data for: 2022-12-01\n",
      "Fetching data for: 2022-12-02\n",
      "Fetching data for: 2022-12-03\n",
      "Fetching data for: 2022-12-04\n",
      "Fetching data for: 2022-12-05\n",
      "Fetching data for: 2022-12-06\n",
      "Fetching data for: 2022-12-07\n",
      "Fetching data for: 2022-12-08\n",
      "Fetching data for: 2022-12-09\n",
      "Fetching data for: 2022-12-10\n",
      "Fetching data for: 2022-12-11\n",
      "Fetching data for: 2022-12-12\n",
      "Fetching data for: 2022-12-13\n",
      "Fetching data for: 2022-12-14\n",
      "Fetching data for: 2022-12-15\n",
      "Fetching data for: 2022-12-16\n",
      "Fetching data for: 2022-12-17\n",
      "Fetching data for: 2022-12-18\n",
      "Fetching data for: 2022-12-19\n",
      "Fetching data for: 2022-12-20\n",
      "Fetching data for: 2022-12-21\n",
      "Fetching data for: 2022-12-22\n",
      "Fetching data for: 2022-12-23\n",
      "Fetching data for: 2022-12-24\n",
      "Fetching data for: 2022-12-25\n",
      "Fetching data for: 2022-12-26\n",
      "Fetching data for: 2022-12-27\n",
      "Fetching data for: 2022-12-28\n",
      "Fetching data for: 2022-12-29\n",
      "Fetching data for: 2022-12-30\n",
      "Fetching data for: 2022-12-31\n",
      "Fetching data for: 2023-01-01\n",
      "Fetching data for: 2023-01-02\n",
      "Fetching data for: 2023-01-03\n",
      "Fetching data for: 2023-01-04\n",
      "Fetching data for: 2023-01-05\n",
      "Fetching data for: 2023-01-06\n",
      "Fetching data for: 2023-01-07\n",
      "Fetching data for: 2023-01-08\n",
      "Fetching data for: 2023-01-09\n",
      "Fetching data for: 2023-01-10\n",
      "Fetching data for: 2023-01-11\n",
      "Fetching data for: 2023-01-12\n",
      "Fetching data for: 2023-01-13\n",
      "Fetching data for: 2023-01-14\n",
      "Fetching data for: 2023-01-15\n",
      "Fetching data for: 2023-01-16\n",
      "Fetching data for: 2023-01-17\n",
      "Fetching data for: 2023-01-18\n",
      "Fetching data for: 2023-01-19\n",
      "Fetching data for: 2023-01-20\n",
      "Fetching data for: 2023-01-21\n",
      "Fetching data for: 2023-01-22\n",
      "Fetching data for: 2023-01-23\n",
      "Fetching data for: 2023-01-24\n",
      "Fetching data for: 2023-01-25\n",
      "Fetching data for: 2023-01-26\n",
      "Fetching data for: 2023-01-27\n",
      "Fetching data for: 2023-01-28\n",
      "Fetching data for: 2023-01-29\n",
      "Fetching data for: 2023-01-30\n",
      "Fetching data for: 2023-01-31\n",
      "Fetching data for: 2023-02-01\n",
      "Fetching data for: 2023-02-02\n",
      "Fetching data for: 2023-02-03\n",
      "Fetching data for: 2023-02-04\n",
      "Fetching data for: 2023-02-05\n",
      "Fetching data for: 2023-02-06\n",
      "Fetching data for: 2023-02-07\n",
      "Fetching data for: 2023-02-08\n",
      "Fetching data for: 2023-02-09\n",
      "Fetching data for: 2023-02-10\n",
      "Fetching data for: 2023-02-11\n",
      "Fetching data for: 2023-02-12\n",
      "Fetching data for: 2023-02-13\n",
      "Fetching data for: 2023-02-14\n",
      "Fetching data for: 2023-02-15\n",
      "Fetching data for: 2023-02-16\n",
      "Fetching data for: 2023-02-17\n",
      "Fetching data for: 2023-02-18\n",
      "Fetching data for: 2023-02-19\n",
      "Fetching data for: 2023-02-20\n",
      "Fetching data for: 2023-02-21\n",
      "Fetching data for: 2023-02-22\n",
      "Fetching data for: 2023-02-23\n",
      "Fetching data for: 2023-02-24\n",
      "Fetching data for: 2023-02-25\n",
      "Fetching data for: 2023-02-26\n",
      "Fetching data for: 2023-02-27\n",
      "Fetching data for: 2023-02-28\n",
      "Fetching data for: 2023-03-01\n",
      "Fetching data for: 2023-03-02\n",
      "Fetching data for: 2023-03-03\n",
      "Fetching data for: 2023-03-04\n",
      "Fetching data for: 2023-03-05\n",
      "Fetching data for: 2023-03-06\n",
      "Fetching data for: 2023-03-07\n",
      "Fetching data for: 2023-03-08\n",
      "Fetching data for: 2023-03-09\n",
      "Fetching data for: 2023-03-10\n",
      "Fetching data for: 2023-03-11\n",
      "Fetching data for: 2023-03-12\n",
      "Fetching data for: 2023-03-13\n",
      "Fetching data for: 2023-03-14\n",
      "Fetching data for: 2023-03-15\n",
      "Fetching data for: 2023-03-16\n",
      "Fetching data for: 2023-03-17\n",
      "Fetching data for: 2023-03-18\n",
      "Fetching data for: 2023-03-19\n",
      "Fetching data for: 2023-03-20\n",
      "Fetching data for: 2023-03-21\n",
      "Fetching data for: 2023-03-22\n",
      "Fetching data for: 2023-03-23\n",
      "Fetching data for: 2023-03-24\n",
      "Fetching data for: 2023-03-25\n",
      "Fetching data for: 2023-03-26\n",
      "Fetching data for: 2023-03-27\n",
      "Fetching data for: 2023-03-28\n",
      "Fetching data for: 2023-03-29\n",
      "Fetching data for: 2023-03-30\n",
      "Fetching data for: 2023-03-31\n",
      "Fetching data for: 2023-04-01\n",
      "Fetching data for: 2023-04-02\n",
      "Fetching data for: 2023-04-03\n",
      "Fetching data for: 2023-04-04\n",
      "Fetching data for: 2023-04-05\n",
      "Fetching data for: 2023-04-06\n",
      "Fetching data for: 2023-04-07\n",
      "Fetching data for: 2023-04-08\n",
      "Fetching data for: 2023-04-09\n",
      "Fetching data for: 2023-04-10\n",
      "Fetching data for: 2023-04-11\n",
      "Fetching data for: 2023-04-12\n",
      "Fetching data for: 2023-04-13\n",
      "Fetching data for: 2023-04-14\n",
      "Fetching data for: 2023-04-15\n",
      "Fetching data for: 2023-04-16\n",
      "Fetching data for: 2023-04-17\n",
      "Fetching data for: 2023-04-18\n",
      "Fetching data for: 2023-04-19\n",
      "Fetching data for: 2023-04-20\n",
      "Fetching data for: 2023-04-21\n",
      "Fetching data for: 2023-04-22\n",
      "Fetching data for: 2023-04-23\n",
      "Fetching data for: 2023-04-24\n",
      "Fetching data for: 2023-04-25\n",
      "Fetching data for: 2023-04-26\n",
      "Fetching data for: 2023-04-27\n",
      "Fetching data for: 2023-04-28\n",
      "Fetching data for: 2023-04-29\n",
      "Fetching data for: 2023-04-30\n",
      "Fetching data for: 2023-05-01\n",
      "Fetching data for: 2023-05-02\n",
      "Fetching data for: 2023-05-03\n",
      "Fetching data for: 2023-05-04\n",
      "Fetching data for: 2023-05-05\n",
      "Fetching data for: 2023-05-06\n",
      "Fetching data for: 2023-05-07\n",
      "Fetching data for: 2023-05-08\n",
      "Fetching data for: 2023-05-09\n",
      "Fetching data for: 2023-05-10\n",
      "Fetching data for: 2023-05-11\n",
      "Fetching data for: 2023-05-12\n",
      "Fetching data for: 2023-05-13\n",
      "Fetching data for: 2023-05-14\n",
      "Fetching data for: 2023-05-15\n",
      "Fetching data for: 2023-05-16\n",
      "Fetching data for: 2023-05-17\n",
      "Fetching data for: 2023-05-18\n",
      "Fetching data for: 2023-05-19\n",
      "Fetching data for: 2023-05-20\n",
      "Fetching data for: 2023-05-21\n",
      "Fetching data for: 2023-05-22\n",
      "Fetching data for: 2023-05-23\n",
      "Fetching data for: 2023-05-24\n",
      "Fetching data for: 2023-05-25\n",
      "Fetching data for: 2023-05-26\n",
      "Fetching data for: 2023-05-27\n",
      "Fetching data for: 2023-05-28\n",
      "Fetching data for: 2023-05-29\n",
      "Fetching data for: 2023-05-30\n",
      "Fetching data for: 2023-05-31\n",
      "Fetching data for: 2023-06-01\n",
      "Fetching data for: 2023-06-02\n",
      "Fetching data for: 2023-06-03\n",
      "Fetching data for: 2023-06-04\n",
      "Fetching data for: 2023-06-05\n",
      "Fetching data for: 2023-06-06\n",
      "Fetching data for: 2023-06-07\n",
      "Fetching data for: 2023-06-08\n",
      "Fetching data for: 2023-06-09\n",
      "Fetching data for: 2023-06-10\n",
      "Fetching data for: 2023-06-11\n",
      "Fetching data for: 2023-06-12\n",
      "Fetching data for: 2023-06-13\n",
      "Fetching data for: 2023-06-14\n",
      "Fetching data for: 2023-06-15\n",
      "Fetching data for: 2023-06-16\n",
      "Fetching data for: 2023-06-17\n",
      "Fetching data for: 2023-06-18\n",
      "Fetching data for: 2023-06-19\n",
      "Fetching data for: 2023-06-20\n",
      "Fetching data for: 2023-06-21\n",
      "Fetching data for: 2023-06-22\n",
      "Fetching data for: 2023-06-23\n",
      "Fetching data for: 2023-06-24\n",
      "Fetching data for: 2023-06-25\n",
      "Fetching data for: 2023-06-26\n",
      "Fetching data for: 2023-06-27\n",
      "Fetching data for: 2023-06-28\n",
      "Fetching data for: 2023-06-29\n",
      "Fetching data for: 2023-06-30\n",
      "Fetching data for: 2023-07-01\n",
      "Fetching data for: 2023-07-02\n",
      "Fetching data for: 2023-07-03\n",
      "Fetching data for: 2023-07-04\n",
      "Fetching data for: 2023-07-05\n",
      "Fetching data for: 2023-07-06\n",
      "Fetching data for: 2023-07-07\n",
      "Fetching data for: 2023-07-08\n",
      "Fetching data for: 2023-07-09\n",
      "Fetching data for: 2023-07-10\n",
      "Fetching data for: 2023-07-11\n",
      "Fetching data for: 2023-07-12\n",
      "Fetching data for: 2023-07-13\n",
      "Fetching data for: 2023-07-14\n",
      "Fetching data for: 2023-07-15\n",
      "Fetching data for: 2023-07-16\n",
      "Fetching data for: 2023-07-17\n",
      "Fetching data for: 2023-07-18\n",
      "Fetching data for: 2023-07-19\n",
      "Fetching data for: 2023-07-20\n",
      "Fetching data for: 2023-07-21\n",
      "Fetching data for: 2023-07-22\n",
      "Fetching data for: 2023-07-23\n",
      "Fetching data for: 2023-07-24\n",
      "Fetching data for: 2023-07-25\n",
      "Fetching data for: 2023-07-26\n",
      "Fetching data for: 2023-07-27\n",
      "Fetching data for: 2023-07-28\n",
      "Fetching data for: 2023-07-29\n",
      "Fetching data for: 2023-07-30\n",
      "Fetching data for: 2023-07-31\n",
      "Fetching data for: 2023-08-01\n",
      "Fetching data for: 2023-08-02\n",
      "Fetching data for: 2023-08-03\n",
      "Fetching data for: 2023-08-04\n",
      "Fetching data for: 2023-08-05\n",
      "Fetching data for: 2023-08-06\n",
      "Fetching data for: 2023-08-07\n",
      "Fetching data for: 2023-08-08\n",
      "Fetching data for: 2023-08-09\n",
      "Fetching data for: 2023-08-10\n",
      "Fetching data for: 2023-08-11\n",
      "Fetching data for: 2023-08-12\n",
      "Fetching data for: 2023-08-13\n",
      "Fetching data for: 2023-08-14\n",
      "Fetching data for: 2023-08-15\n",
      "Fetching data for: 2023-08-16\n",
      "Fetching data for: 2023-08-17\n",
      "Fetching data for: 2023-08-18\n",
      "Fetching data for: 2023-08-19\n",
      "Fetching data for: 2023-08-20\n",
      "Fetching data for: 2023-08-21\n",
      "Fetching data for: 2023-08-22\n",
      "Fetching data for: 2023-08-23\n",
      "Fetching data for: 2023-08-24\n",
      "Fetching data for: 2023-08-25\n",
      "Fetching data for: 2023-08-26\n",
      "Fetching data for: 2023-08-27\n",
      "Fetching data for: 2023-08-28\n",
      "Fetching data for: 2023-08-29\n",
      "Fetching data for: 2023-08-30\n",
      "Fetching data for: 2023-08-31\n",
      "Fetching data for: 2023-09-01\n",
      "Fetching data for: 2023-09-02\n",
      "Fetching data for: 2023-09-03\n",
      "Fetching data for: 2023-09-04\n",
      "Fetching data for: 2023-09-05\n",
      "Fetching data for: 2023-09-06\n",
      "Fetching data for: 2023-09-07\n",
      "Fetching data for: 2023-09-08\n",
      "Fetching data for: 2023-09-09\n",
      "Fetching data for: 2023-09-10\n",
      "Fetching data for: 2023-09-11\n",
      "Fetching data for: 2023-09-12\n",
      "Fetching data for: 2023-09-13\n",
      "Fetching data for: 2023-09-14\n",
      "Fetching data for: 2023-09-15\n",
      "Fetching data for: 2023-09-16\n",
      "Fetching data for: 2023-09-17\n",
      "Fetching data for: 2023-09-18\n",
      "Fetching data for: 2023-09-19\n",
      "Fetching data for: 2023-09-20\n",
      "Fetching data for: 2023-09-21\n",
      "Fetching data for: 2023-09-22\n",
      "Fetching data for: 2023-09-23\n",
      "Fetching data for: 2023-09-24\n",
      "Fetching data for: 2023-09-25\n",
      "Fetching data for: 2023-09-26\n",
      "Fetching data for: 2023-09-27\n",
      "Fetching data for: 2023-09-28\n",
      "Fetching data for: 2023-09-29\n",
      "Fetching data for: 2023-09-30\n",
      "Fetching data for: 2023-10-01\n",
      "Fetching data for: 2023-10-02\n",
      "Fetching data for: 2023-10-03\n",
      "Fetching data for: 2023-10-04\n",
      "Fetching data for: 2023-10-05\n",
      "Fetching data for: 2023-10-06\n",
      "Fetching data for: 2023-10-07\n",
      "Fetching data for: 2023-10-08\n",
      "Fetching data for: 2023-10-09\n",
      "Fetching data for: 2023-10-10\n",
      "Fetching data for: 2023-10-11\n",
      "Fetching data for: 2023-10-12\n",
      "Fetching data for: 2023-10-13\n",
      "Fetching data for: 2023-10-14\n",
      "Fetching data for: 2023-10-15\n",
      "Fetching data for: 2023-10-16\n",
      "Fetching data for: 2023-10-17\n",
      "Fetching data for: 2023-10-18\n",
      "Fetching data for: 2023-10-19\n",
      "Fetching data for: 2023-10-20\n",
      "Fetching data for: 2023-10-21\n",
      "Fetching data for: 2023-10-22\n",
      "Fetching data for: 2023-10-23\n",
      "Fetching data for: 2023-10-24\n",
      "Fetching data for: 2023-10-25\n",
      "Fetching data for: 2023-10-26\n",
      "Fetching data for: 2023-10-27\n",
      "Fetching data for: 2023-10-28\n",
      "Fetching data for: 2023-10-29\n",
      "Fetching data for: 2023-10-30\n",
      "Fetching data for: 2023-10-31\n",
      "Fetching data for: 2023-11-01\n",
      "Fetching data for: 2023-11-02\n",
      "Fetching data for: 2023-11-03\n",
      "Fetching data for: 2023-11-04\n",
      "Fetching data for: 2023-11-05\n",
      "Fetching data for: 2023-11-06\n",
      "Fetching data for: 2023-11-07\n",
      "Fetching data for: 2023-11-08\n",
      "Fetching data for: 2023-11-09\n",
      "Fetching data for: 2023-11-10\n",
      "Fetching data for: 2023-11-11\n",
      "Fetching data for: 2023-11-12\n",
      "Fetching data for: 2023-11-13\n",
      "Fetching data for: 2023-11-14\n",
      "Fetching data for: 2023-11-15\n",
      "Fetching data for: 2023-11-16\n",
      "Fetching data for: 2023-11-17\n",
      "Fetching data for: 2023-11-18\n",
      "Fetching data for: 2023-11-19\n",
      "Fetching data for: 2023-11-20\n",
      "Fetching data for: 2023-11-21\n",
      "Fetching data for: 2023-11-22\n",
      "Fetching data for: 2023-11-23\n",
      "Fetching data for: 2023-11-24\n",
      "Fetching data for: 2023-11-25\n",
      "Fetching data for: 2023-11-26\n",
      "Fetching data for: 2023-11-27\n",
      "Fetching data for: 2023-11-28\n",
      "Fetching data for: 2023-11-29\n",
      "Fetching data for: 2023-11-30\n",
      "Fetching data for: 2023-12-01\n",
      "Fetching data for: 2023-12-02\n",
      "Fetching data for: 2023-12-03\n",
      "Fetching data for: 2023-12-04\n",
      "Fetching data for: 2023-12-05\n",
      "Fetching data for: 2023-12-06\n",
      "Fetching data for: 2023-12-07\n",
      "Fetching data for: 2023-12-08\n",
      "Fetching data for: 2023-12-09\n",
      "Fetching data for: 2023-12-10\n",
      "Fetching data for: 2023-12-11\n",
      "Fetching data for: 2023-12-12\n",
      "Fetching data for: 2023-12-13\n",
      "Fetching data for: 2023-12-14\n",
      "Fetching data for: 2023-12-15\n",
      "Fetching data for: 2023-12-16\n",
      "Fetching data for: 2023-12-17\n",
      "Fetching data for: 2023-12-18\n",
      "Fetching data for: 2023-12-19\n",
      "Fetching data for: 2023-12-20\n",
      "Fetching data for: 2023-12-21\n",
      "Fetching data for: 2023-12-22\n",
      "Fetching data for: 2023-12-23\n",
      "Fetching data for: 2023-12-24\n",
      "Fetching data for: 2023-12-25\n",
      "Fetching data for: 2023-12-26\n",
      "Fetching data for: 2023-12-27\n",
      "Fetching data for: 2023-12-28\n",
      "Fetching data for: 2023-12-29\n",
      "Fetching data for: 2023-12-30\n",
      "Fetching data for: 2023-12-31\n",
      "Fetching data for: 2024-01-01\n",
      "Fetching data for: 2024-01-02\n",
      "Fetching data for: 2024-01-03\n",
      "Fetching data for: 2024-01-04\n",
      "Fetching data for: 2024-01-05\n",
      "Fetching data for: 2024-01-06\n",
      "Fetching data for: 2024-01-07\n",
      "Fetching data for: 2024-01-08\n",
      "Fetching data for: 2024-01-09\n",
      "Fetching data for: 2024-01-10\n",
      "Fetching data for: 2024-01-11\n",
      "Fetching data for: 2024-01-12\n",
      "Fetching data for: 2024-01-13\n",
      "Fetching data for: 2024-01-14\n",
      "Fetching data for: 2024-01-15\n",
      "Fetching data for: 2024-01-16\n",
      "Fetching data for: 2024-01-17\n",
      "Fetching data for: 2024-01-18\n",
      "Fetching data for: 2024-01-19\n",
      "Fetching data for: 2024-01-20\n",
      "Fetching data for: 2024-01-21\n",
      "Fetching data for: 2024-01-22\n",
      "Fetching data for: 2024-01-23\n",
      "Fetching data for: 2024-01-24\n",
      "Fetching data for: 2024-01-25\n",
      "Fetching data for: 2024-01-26\n",
      "Fetching data for: 2024-01-27\n",
      "Fetching data for: 2024-01-28\n",
      "Fetching data for: 2024-01-29\n",
      "Fetching data for: 2024-01-30\n",
      "Fetching data for: 2024-01-31\n",
      "Fetching data for: 2024-02-01\n",
      "Fetching data for: 2024-02-02\n",
      "Fetching data for: 2024-02-03\n",
      "Fetching data for: 2024-02-04\n",
      "Fetching data for: 2024-02-05\n",
      "Fetching data for: 2024-02-06\n",
      "Fetching data for: 2024-02-07\n",
      "Fetching data for: 2024-02-08\n",
      "Fetching data for: 2024-02-09\n",
      "Fetching data for: 2024-02-10\n",
      "Fetching data for: 2024-02-11\n",
      "Fetching data for: 2024-02-12\n",
      "Fetching data for: 2024-02-13\n",
      "Fetching data for: 2024-02-14\n",
      "Fetching data for: 2024-02-15\n",
      "Fetching data for: 2024-02-16\n",
      "Fetching data for: 2024-02-17\n",
      "Fetching data for: 2024-02-18\n",
      "Fetching data for: 2024-02-19\n",
      "Fetching data for: 2024-02-20\n",
      "Fetching data for: 2024-02-21\n",
      "Fetching data for: 2024-02-22\n",
      "Fetching data for: 2024-02-23\n",
      "Fetching data for: 2024-02-24\n",
      "Fetching data for: 2024-02-25\n",
      "Fetching data for: 2024-02-26\n",
      "Fetching data for: 2024-02-27\n",
      "Fetching data for: 2024-02-28\n",
      "Fetching data for: 2024-02-29\n",
      "Fetching data for: 2024-03-01\n",
      "Fetching data for: 2024-03-02\n",
      "Fetching data for: 2024-03-03\n",
      "Fetching data for: 2024-03-04\n",
      "Fetching data for: 2024-03-05\n",
      "Fetching data for: 2024-03-06\n",
      "Fetching data for: 2024-03-07\n",
      "Fetching data for: 2024-03-08\n",
      "Fetching data for: 2024-03-09\n",
      "Fetching data for: 2024-03-10\n",
      "Fetching data for: 2024-03-11\n",
      "Fetching data for: 2024-03-12\n",
      "Fetching data for: 2024-03-13\n",
      "Fetching data for: 2024-03-14\n",
      "Fetching data for: 2024-03-15\n",
      "Fetching data for: 2024-03-16\n",
      "Fetching data for: 2024-03-17\n",
      "Fetching data for: 2024-03-18\n",
      "Fetching data for: 2024-03-19\n",
      "Fetching data for: 2024-03-20\n",
      "Fetching data for: 2024-03-21\n",
      "Fetching data for: 2024-03-22\n",
      "Fetching data for: 2024-03-23\n",
      "Fetching data for: 2024-03-24\n",
      "Fetching data for: 2024-03-25\n",
      "Fetching data for: 2024-03-26\n",
      "Fetching data for: 2024-03-27\n",
      "Fetching data for: 2024-03-28\n",
      "Fetching data for: 2024-03-29\n",
      "Fetching data for: 2024-03-30\n",
      "Fetching data for: 2024-03-31\n",
      "Fetching data for: 2024-04-01\n",
      "Fetching data for: 2024-04-02\n",
      "Fetching data for: 2024-04-03\n",
      "Fetching data for: 2024-04-04\n",
      "Fetching data for: 2024-04-05\n",
      "Fetching data for: 2024-04-06\n",
      "Fetching data for: 2024-04-07\n",
      "Fetching data for: 2024-04-08\n",
      "Fetching data for: 2024-04-09\n",
      "Fetching data for: 2024-04-10\n",
      "Fetching data for: 2024-04-11\n",
      "Fetching data for: 2024-04-12\n",
      "Fetching data for: 2024-04-13\n",
      "Fetching data for: 2024-04-14\n",
      "Fetching data for: 2024-04-15\n",
      "Fetching data for: 2024-04-16\n",
      "Fetching data for: 2024-04-17\n",
      "Fetching data for: 2024-04-18\n",
      "Fetching data for: 2024-04-19\n",
      "Fetching data for: 2024-04-20\n",
      "Fetching data for: 2024-04-21\n",
      "Fetching data for: 2024-04-22\n",
      "Fetching data for: 2024-04-23\n",
      "Fetching data for: 2024-04-24\n",
      "Fetching data for: 2024-04-25\n",
      "Fetching data for: 2024-04-26\n",
      "Fetching data for: 2024-04-27\n",
      "Fetching data for: 2024-04-28\n",
      "Fetching data for: 2024-04-29\n",
      "Fetching data for: 2024-04-30\n",
      "Fetching data for: 2024-05-01\n",
      "Fetching data for: 2024-05-02\n",
      "Fetching data for: 2024-05-03\n",
      "Fetching data for: 2024-05-04\n",
      "Fetching data for: 2024-05-05\n",
      "Fetching data for: 2024-05-06\n",
      "Fetching data for: 2024-05-07\n",
      "Fetching data for: 2024-05-08\n",
      "Fetching data for: 2024-05-09\n",
      "Fetching data for: 2024-05-10\n",
      "Fetching data for: 2024-05-11\n",
      "Fetching data for: 2024-05-12\n",
      "Fetching data for: 2024-05-13\n",
      "Fetching data for: 2024-05-14\n",
      "Fetching data for: 2024-05-15\n",
      "Fetching data for: 2024-05-16\n",
      "Fetching data for: 2024-05-17\n",
      "Fetching data for: 2024-05-18\n",
      "Fetching data for: 2024-05-19\n",
      "Fetching data for: 2024-05-20\n",
      "Fetching data for: 2024-05-21\n",
      "Fetching data for: 2024-05-22\n",
      "Fetching data for: 2024-05-23\n",
      "Fetching data for: 2024-05-24\n",
      "Fetching data for: 2024-05-25\n",
      "Fetching data for: 2024-05-26\n",
      "Fetching data for: 2024-05-27\n",
      "Fetching data for: 2024-05-28\n",
      "Fetching data for: 2024-05-29\n",
      "Fetching data for: 2024-05-30\n",
      "Fetching data for: 2024-05-31\n",
      "Fetching data for: 2024-06-01\n",
      "Fetching data for: 2024-06-02\n",
      "Fetching data for: 2024-06-03\n",
      "Fetching data for: 2024-06-04\n",
      "Fetching data for: 2024-06-05\n",
      "Fetching data for: 2024-06-06\n",
      "Fetching data for: 2024-06-07\n",
      "Fetching data for: 2024-06-08\n",
      "Fetching data for: 2024-06-09\n",
      "Fetching data for: 2024-06-10\n",
      "Fetching data for: 2024-06-11\n",
      "Fetching data for: 2024-06-12\n",
      "Fetching data for: 2024-06-13\n",
      "Fetching data for: 2024-06-14\n",
      "Fetching data for: 2024-06-15\n",
      "Fetching data for: 2024-06-16\n",
      "Fetching data for: 2024-06-17\n",
      "Fetching data for: 2024-06-18\n",
      "Fetching data for: 2024-06-19\n",
      "Fetching data for: 2024-06-20\n",
      "Fetching data for: 2024-06-21\n",
      "Fetching data for: 2024-06-22\n",
      "Fetching data for: 2024-06-23\n",
      "Fetching data for: 2024-06-24\n",
      "Fetching data for: 2024-06-25\n",
      "Fetching data for: 2024-06-26\n",
      "Fetching data for: 2024-06-27\n",
      "Fetching data for: 2024-06-28\n",
      "Fetching data for: 2024-06-29\n",
      "Fetching data for: 2024-06-30\n",
      "Fetching data for: 2024-07-01\n",
      "Fetching data for: 2024-07-02\n",
      "Fetching data for: 2024-07-03\n",
      "Fetching data for: 2024-07-04\n",
      "Fetching data for: 2024-07-05\n",
      "Fetching data for: 2024-07-06\n",
      "Fetching data for: 2024-07-07\n",
      "Fetching data for: 2024-07-08\n",
      "Fetching data for: 2024-07-09\n",
      "Fetching data for: 2024-07-10\n",
      "Fetching data for: 2024-07-11\n",
      "Fetching data for: 2024-07-12\n",
      "Fetching data for: 2024-07-13\n",
      "Fetching data for: 2024-07-14\n",
      "Fetching data for: 2024-07-15\n",
      "Fetching data for: 2024-07-16\n",
      "Fetching data for: 2024-07-17\n",
      "Fetching data for: 2024-07-18\n",
      "Fetching data for: 2024-07-19\n",
      "Fetching data for: 2024-07-20\n",
      "Fetching data for: 2024-07-21\n",
      "Fetching data for: 2024-07-22\n",
      "Fetching data for: 2024-07-23\n",
      "Fetching data for: 2024-07-24\n",
      "Fetching data for: 2024-07-25\n",
      "Fetching data for: 2024-07-26\n",
      "Fetching data for: 2024-07-27\n",
      "Fetching data for: 2024-07-28\n",
      "Fetching data for: 2024-07-29\n",
      "Fetching data for: 2024-07-30\n",
      "Fetching data for: 2024-07-31\n",
      "Fetching data for: 2024-08-01\n",
      "Fetching data for: 2024-08-02\n",
      "Fetching data for: 2024-08-03\n",
      "Fetching data for: 2024-08-04\n",
      "Fetching data for: 2024-08-05\n",
      "Fetching data for: 2024-08-06\n",
      "Fetching data for: 2024-08-07\n",
      "Fetching data for: 2024-08-08\n",
      "Fetching data for: 2024-08-09\n",
      "Fetching data for: 2024-08-10\n",
      "Fetching data for: 2024-08-11\n",
      "Fetching data for: 2024-08-12\n",
      "Fetching data for: 2024-08-13\n",
      "Fetching data for: 2024-08-14\n",
      "Fetching data for: 2024-08-15\n",
      "Fetching data for: 2024-08-16\n",
      "Fetching data for: 2024-08-17\n",
      "Fetching data for: 2024-08-18\n",
      "Fetching data for: 2024-08-19\n",
      "Fetching data for: 2024-08-20\n",
      "Fetching data for: 2024-08-21\n",
      "Fetching data for: 2024-08-22\n",
      "Fetching data for: 2024-08-23\n",
      "Fetching data for: 2024-08-24\n",
      "Fetching data for: 2024-08-25\n",
      "Fetching data for: 2024-08-26\n",
      "Fetching data for: 2024-08-27\n",
      "Fetching data for: 2024-08-28\n",
      "Fetching data for: 2024-08-29\n",
      "Fetching data for: 2024-08-30\n",
      "Fetching data for: 2024-08-31\n",
      "Fetching data for: 2024-09-01\n",
      "Fetching data for: 2024-09-02\n",
      "Fetching data for: 2024-09-03\n",
      "Fetching data for: 2024-09-04\n",
      "Fetching data for: 2024-09-05\n",
      "Fetching data for: 2024-09-06\n",
      "Fetching data for: 2024-09-07\n",
      "Fetching data for: 2024-09-08\n",
      "Fetching data for: 2024-09-09\n",
      "Fetching data for: 2024-09-10\n",
      "Fetching data for: 2024-09-11\n",
      "Fetching data for: 2024-09-12\n",
      "Fetching data for: 2024-09-13\n",
      "Fetching data for: 2024-09-14\n",
      "Fetching data for: 2024-09-15\n",
      "Fetching data for: 2024-09-16\n",
      "Fetching data for: 2024-09-17\n",
      "Fetching data for: 2024-09-18\n",
      "Fetching data for: 2024-09-19\n",
      "Fetching data for: 2024-09-20\n",
      "Fetching data for: 2024-09-21\n",
      "Fetching data for: 2024-09-22\n",
      "Fetching data for: 2024-09-23\n",
      "Fetching data for: 2024-09-24\n",
      "Fetching data for: 2024-09-25\n",
      "Fetching data for: 2024-09-26\n",
      "Fetching data for: 2024-09-27\n",
      "Fetching data for: 2024-09-28\n",
      "Fetching data for: 2024-09-29\n",
      "Fetching data for: 2024-09-30\n",
      "Fetching data for: 2024-10-01\n",
      "Fetching data for: 2024-10-02\n",
      "Fetching data for: 2024-10-03\n",
      "Fetching data for: 2024-10-04\n",
      "Fetching data for: 2024-10-05\n",
      "Fetching data for: 2024-10-06\n",
      "Fetching data for: 2024-10-07\n",
      "Fetching data for: 2024-10-08\n",
      "Fetching data for: 2024-10-09\n",
      "Fetching data for: 2024-10-10\n",
      "Fetching data for: 2024-10-11\n",
      "Fetching data for: 2024-10-12\n",
      "Fetching data for: 2024-10-13\n",
      "Fetching data for: 2024-10-14\n",
      "Fetching data for: 2024-10-15\n",
      "Fetching data for: 2024-10-16\n",
      "Fetching data for: 2024-10-17\n",
      "Fetching data for: 2024-10-18\n",
      "Fetching data for: 2024-10-19\n",
      "Fetching data for: 2024-10-20\n",
      "Fetching data for: 2024-10-21\n",
      "Fetching data for: 2024-10-22\n",
      "Fetching data for: 2024-10-23\n",
      "Fetching data for: 2024-10-24\n",
      "Fetching data for: 2024-10-25\n",
      "Fetching data for: 2024-10-26\n",
      "Fetching data for: 2024-10-27\n",
      "Fetching data for: 2024-10-28\n",
      "Fetching data for: 2024-10-29\n",
      "Fetching data for: 2024-10-30\n",
      "Fetching data for: 2024-10-31\n",
      "Fetching data for: 2024-11-01\n",
      "Fetching data for: 2024-11-02\n",
      "Fetching data for: 2024-11-03\n",
      "Fetching data for: 2024-11-04\n",
      "Fetching data for: 2024-11-05\n",
      "Fetching data for: 2024-11-06\n",
      "Fetching data for: 2024-11-07\n",
      "Fetching data for: 2024-11-08\n",
      "Fetching data for: 2024-11-09\n",
      "Fetching data for: 2024-11-10\n",
      "Fetching data for: 2024-11-11\n",
      "Fetching data for: 2024-11-12\n",
      "Fetching data for: 2024-11-13\n",
      "Fetching data for: 2024-11-14\n",
      "Fetching data for: 2024-11-15\n",
      "Fetching data for: 2024-11-16\n",
      "Fetching data for: 2024-11-17\n",
      "Fetching data for: 2024-11-18\n",
      "Fetching data for: 2024-11-19\n",
      "Fetching data for: 2024-11-20\n",
      "Fetching data for: 2024-11-21\n",
      "Fetching data for: 2024-11-22\n",
      "Fetching data for: 2024-11-23\n",
      "Fetching data for: 2024-11-24\n",
      "Fetching data for: 2024-11-25\n",
      "Fetching data for: 2024-11-26\n",
      "Fetching data for: 2024-11-27\n",
      "Fetching data for: 2024-11-28\n",
      "Fetching data for: 2024-11-29\n",
      "Fetching data for: 2024-11-30\n",
      "Fetching data for: 2024-12-01\n",
      "Fetching data for: 2024-12-02\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time  # Import the time module for sleep function\n",
    "\n",
    "api_key = 'f3e342dc-477b-4784-bba2-a0916569947b'\n",
    "base_url = 'https://content.guardianapis.com/search'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "def get_news_data(start_date, end_date):\n",
    "    news_data = []\n",
    "    current_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "\n",
    "    while current_date <= datetime.strptime(end_date, '%Y-%m-%d'):\n",
    "        date_str = current_date.strftime('%Y-%m-%d')\n",
    "        print(f\"Fetching data for: {date_str}\")\n",
    "        \n",
    "        params = {\n",
    "            'section': 'business',\n",
    "            'page-size': 200,\n",
    "            'from-date': date_str,\n",
    "            'to-date': date_str,\n",
    "            'show-fields': 'body',\n",
    "            'api-key': api_key,\n",
    "        }\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            results = response.json().get(\"response\", {}).get(\"results\", [])\n",
    "            for article in results:\n",
    "                if \"fields\" in article and \"body\" in article[\"fields\"]:\n",
    "                    news_data.append({'date': date_str, 'content': article[\"fields\"][\"body\"]})\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {date_str}: {response.status_code}\")\n",
    "        \n",
    "        current_date += timedelta(days=1)\n",
    "        time.sleep(1)  # Respect API rate limits\n",
    "    \n",
    "    return pd.DataFrame(news_data)\n",
    "\n",
    "news_df = get_news_data(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         date                                            content\n",
       " 0  2022-10-01  <p>Will it be a merry Christmas? It will certa...\n",
       " 1  2022-10-01  <p>The owner of British Steel, the UK’s second...\n",
       " 2  2022-10-01  <p>A former steelworks in Redcar has been pull...\n",
       " 3  2022-10-01  <p>Thousands of supporters of Just Stop Oil ha...\n",
       " 4  2022-10-01  <p>‘You haven’t been in the office this week. ...,\n",
       "             date                                            content\n",
       " 7841  2024-12-02  <div id=\"block-674d5f3f8f08613772568f0c\" class...\n",
       " 7842  2024-12-02  <p>Global carbon emissions would be 6% lower t...\n",
       " 7843  2024-12-02  <p>Workers at Volkswagen factories in Germany ...\n",
       " 7844  2024-12-02  <p>More than 1,500 Woolworths warehouse worker...\n",
       " 7845  2024-12-02  <p>Growth expectations among UK companies have...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(), news_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\RUTHVIK\n",
      "[nltk_data]     REDDY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date                                            content  sentiment\n",
      "0  2022-10-01  <p>Will it be a merry Christmas? It will certa...     0.6407\n",
      "1  2022-10-01  <p>The owner of British Steel, the UK’s second...     0.9946\n",
      "2  2022-10-01  <p>A former steelworks in Redcar has been pull...     0.9603\n",
      "3  2022-10-01  <p>Thousands of supporters of Just Stop Oil ha...     0.9480\n",
      "4  2022-10-01  <p>‘You haven’t been in the office this week. ...     0.9923\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Download the VADER lexicon (only needed once)\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define the sentiment analysis function\n",
    "def analyze_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']  # Use compound score for overall sentiment\n",
    "\n",
    "# Apply the function to your news DataFrame\n",
    "news_df['sentiment'] = news_df['content'].apply(analyze_sentiment)\n",
    "print(news_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News data saved to news_data.csv\n"
     ]
    }
   ],
   "source": [
    "csv_filename = \"news_data.csv\"\n",
    "news_df.to_csv(csv_filename, index=False)\n",
    "print(f\"News data saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  avg_sentiment\n",
      "0  2022-10-01       0.534844\n",
      "1  2022-10-02       0.156289\n",
      "2  2022-10-03       0.150150\n",
      "3  2022-10-04       0.754340\n",
      "4  2022-10-05       0.475950\n"
     ]
    }
   ],
   "source": [
    "news_sentiment_avg = news_df.groupby('date')['sentiment'].mean().reset_index()\n",
    "news_sentiment_avg.rename(columns={'sentiment': 'avg_sentiment'}, inplace=True)\n",
    "print(news_sentiment_avg.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News data saved to news_avg_sentiment_data.csv\n"
     ]
    }
   ],
   "source": [
    "csv_filename = \"news_avg_sentiment_data.csv\"\n",
    "news_sentiment_avg.to_csv(csv_filename, index=False)\n",
    "print(f\"News data saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock DataFrame columns: Index(['Date', 'Close'], dtype='object')\n",
      "News Sentiment DataFrame columns: Index(['date', 'avg_sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Stock DataFrame columns:\", stock_data.columns)\n",
    "print(\"News Sentiment DataFrame columns:\", news_sentiment_avg.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"stock_sentiment_data.csv\")\n",
    "\n",
    "df.drop(columns=['date', 'avg_sentiment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"stock_sentiment_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data has been saved to 'merged_stock_sentiment_data.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda_tmp\\ipykernel_24532\\1512537593.py:18: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data['Close'] = merged_data['Close'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "stocks_data = pd.read_csv('stock_data.csv', parse_dates=['Date'])\n",
    "news_sentiment_data = pd.read_csv('news_avg_sentiment_data.csv', parse_dates=['date'])\n",
    "\n",
    "# Rename the 'date' column in news_sentiment_data to 'Date' for consistency\n",
    "news_sentiment_data.rename(columns={'date': 'Date'}, inplace=True)\n",
    "\n",
    "# Ensure unique dates by dropping duplicates (if any)\n",
    "stocks_data = stocks_data.drop_duplicates(subset=['Date'])\n",
    "news_sentiment_data = news_sentiment_data.drop_duplicates(subset=['Date'])\n",
    "\n",
    "# Merge the dataframes based on news dates ('Date' from news_sentiment_data)\n",
    "merged_data = pd.merge(news_sentiment_data, stocks_data, on='Date', how='left')\n",
    "\n",
    "# Forward fill missing stock values (using the previous day's stock value)\n",
    "merged_data['Close'] = merged_data['Close'].fillna(method='ffill')\n",
    "\n",
    "# Remove any duplicate dates that might have appeared after merging\n",
    "merged_data = merged_data.drop_duplicates(subset=['Date'])\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "merged_data.to_csv('merged_stock_sentiment_data.csv', index=False)\n",
    "\n",
    "print(\"Merged data has been saved to 'merged_stock_sentiment_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
